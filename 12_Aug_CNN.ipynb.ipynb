{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1)Describe the purpose and benefits of pooling in CNN"
      ],
      "metadata": {
        "id": "DWIW4meMsHN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling is a technique in Convolutional Neural Networks (CNNs) that involves downsampling feature maps to reduce their spatial dimensions while retaining essential information. The primary purpose of pooling is to decrease the computational complexity of the network and control overfitting, leading to several benefits:\n",
        "\n",
        "Dimensionality Reduction: Pooling reduces the size of feature maps, making computations more manageable and efficient. This helps in processing larger images without an excessive increase in computational resources.\n",
        "\n",
        "Translation Invariance: Pooling helps the network recognize patterns irrespective of their precise location in the input image. It achieves this by summarizing local information into a single representative value.\n",
        "\n",
        "Feature Retention: While pooling reduces spatial dimensions, it retains important features by selecting prominent values within pooling regions. This aids in preserving crucial information while discarding less relevant details.\n",
        "\n",
        "Improved Generalization: Pooling helps prevent overfitting by reducing the risk of the model memorizing noise or irrelevant details present in the training data. It encourages the network to learn more robust and generalizable features.\n"
      ],
      "metadata": {
        "id": "qsqx8dn9sTIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2)Explain the difference between min pooling and max pooling"
      ],
      "metadata": {
        "id": "od6Er_qksf3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average Pooling: In average pooling, each pooling region is replaced by the average of the values within that region. It smooths out the feature map, reducing the impact of outliers and noise. It is more tolerant to minor variations in the input.\n",
        "\n",
        "Max Pooling: In max pooling, each pooling region is replaced by the maximum value within that region. It focuses on the most prominent feature, emphasizing its presence in the region. Max pooling is effective in capturing dominant patterns.\n"
      ],
      "metadata": {
        "id": "63sxiG0EszPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3)Discuss the concept of padding in CNN and its significance"
      ],
      "metadata": {
        "id": "I0_aYOG7s8N6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding involves adding extra elements (usually zeros) around the edges of an input feature map before applying convolution or pooling operations. The significance of padding includes:\n",
        "\n",
        "Preserving Spatial Dimensions: Padding ensures that the spatial dimensions of the feature maps are maintained after convolutional operations, allowing for deeper architectures without rapidly shrinking the output.\n",
        "\n",
        "Reducing Border Effects: Without padding, the convolutional filter might only cover the central portions of the input, resulting in loss of information at the borders. Padding mitigates this issue by allowing filters to fully cover the input.\n",
        "\n",
        "Controlling Output Size: By adjusting the amount of padding, you can control the size of the output feature maps, which can be crucial for network design and compatibility with subsequent layers.\n"
      ],
      "metadata": {
        "id": "QwIFbhcitBmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4)Compare and contrast zero-padding and valid-padding in terns of their effects on the output"
      ],
      "metadata": {
        "id": "7AONAZnstG49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero-padding: In zero-padding, extra rows and columns of zeros are added around the input feature map. It maintains the spatial dimensions of the output feature map after convolution.\n",
        "\n",
        "Valid-padding: In valid-padding, no padding is added. The filter is only applied to regions of the input where it completely overlaps. This results in a smaller output feature map compared to the input.\n",
        "\n",
        "The choice between zero-padding and valid-padding affects the size of the output feature map and the receptive field of each neuron, which impacts the network's ability to capture different levels of features.\n"
      ],
      "metadata": {
        "id": "7527ZB5PtIPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5)Provide a brief oveview of LeNet-5 architecture"
      ],
      "metadata": {
        "id": "oOpbV3Z5tSjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet-5 is an early CNN architecture developed by Yann Lecun in the 1990s. It was designed for handwritten digit recognition and consists of several layers:\n",
        "\n",
        "Input Layer: Accepts grayscale images.\n",
        "Convolutional Layers: Extract features using convolutional filters.\n",
        "Subsampling (Pooling) Layers: Downsample the feature maps.\n",
        "Fully Connected Layers: Combine features for classification.\n",
        "Output Layer: Produces classification results."
      ],
      "metadata": {
        "id": "w_cnOV-StSf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6)Describe the key components of LeNet-5 and their respective purposes"
      ],
      "metadata": {
        "id": "meTgUV07tcb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Layers: Extract features from the input image using convolutional filters, enabling the network to learn hierarchical patterns.\n",
        "Subsampling Layers: Reduce the dimensionality of feature maps and increase translation invariance by downsampling.\n",
        "Fully Connected Layers: Combine features from previous layers for classification into specific classes.\n",
        "Output Layer: Produce the final classification probabilities."
      ],
      "metadata": {
        "id": "NLYOJzKRtds4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7)Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks"
      ],
      "metadata": {
        "id": "yYeUrv8pthjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages:\n",
        "\n",
        "Pioneered the use of CNNs for image recognition tasks.\n",
        "Effective for simple image classification tasks, especially handwritten digit recognition.\n",
        "Introduced the concept of convolutional and pooling layers for feature extraction.\n",
        "Limitations:\n",
        "\n",
        "Limited capacity for handling complex images and intricate object recognition due to its simplicity.\n",
        "May struggle with more challenging datasets compared to modern architectures."
      ],
      "metadata": {
        "id": "dFJ4ZynTtjGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8)Implement LeNet-5 using a deep learning framework of  TensorFlow and train it on a public available dataset (e.g., MNIST). Evaluate its performance and provide insights."
      ],
      "metadata": {
        "id": "lKBc1N1YuaDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n"
      ],
      "metadata": {
        "id": "xGvvaM8I0WbX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(6, (5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(16, (5, 5), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(120, activation='relu'),\n",
        "    layers.Dense(84, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # 10 classes for MNIST\n",
        "])\n"
      ],
      "metadata": {
        "id": "c_8Qn0aL0a9y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "N1OuXvgH0cyG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n"
      ],
      "metadata": {
        "id": "64HZK91F0ete"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=1, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8w330JJ0nK5",
        "outputId": "54622f2a-c685-4dee-9a7d-6d7827eab223"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0803 - accuracy: 0.9752 - val_loss: 0.0680 - val_accuracy: 0.9794\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79fb392f6f50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9) Present an overview of the AlexNet architecture"
      ],
      "metadata": {
        "id": "EQyN5ueJt8AD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlexNet is a pioneering deep CNN architecture designed by Alex Krizhevsky et al. It won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012. The architecture consists of eight layers: five convolutional layers followed by three fully connected layers."
      ],
      "metadata": {
        "id": "b7W--5i-t9Zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10)Explain the architectural innovations introduced in AlexNet that contributed to its breakthrough performance"
      ],
      "metadata": {
        "id": "o3DNBlq5t9WB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlexNet introduced several innovations that contributed to its breakthrough performance:\n",
        "\n",
        "Deep Architecture: AlexNet used a deep architecture with multiple convolutional and fully connected layers, allowing it to learn complex features and hierarchies of abstraction.\n",
        "\n",
        "ReLU Activation: Rectified Linear Units (ReLU) were used as activation functions, mitigating the vanishing gradient problem and accelerating convergence during training.\n",
        "\n",
        "Data Augmentation: The training data was augmented with techniques like cropping, flipping, and altering brightness, effectively increasing the diversity of training samples.\n",
        "\n",
        "Dropout: Dropout was introduced in fully connected layers, randomly dropping units during training to reduce overfitting."
      ],
      "metadata": {
        "id": "w6zvjJJQt9Mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11)Discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet"
      ],
      "metadata": {
        "id": "7Ph5oEu6t9Gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Layers: Extract hierarchical features using convolutional filters. The depth of these layers captures increasingly complex features.\n",
        "\n",
        "Pooling Layers: Perform downsampling to reduce spatial dimensions and enhance translation invariance."
      ],
      "metadata": {
        "id": "CwNfekbduFls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12)Implement AlexNet using a deep learning framework of your choice and evaluate its performance on a dataset of your choice."
      ],
      "metadata": {
        "id": "RVU05DWquFiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "kYGrTcca1QHX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the AlexNet architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
        "    layers.Conv2D(256, (5, 5), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
        "    layers.Conv2D(384, (3, 3), activation='relu', padding='same'),\n",
        "    layers.Conv2D(384, (3, 3), activation='relu', padding='same'),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(4096, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(4096, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')  # 10 classes for CIFAR-10\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ll0owx4f1pSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate its performance\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "91OgtXjh1YrX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}